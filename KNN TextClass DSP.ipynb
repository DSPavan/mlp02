{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3571c402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT CLASSIFICATION USING KNN\n",
    "# fetch_20newsgroups, \n",
    "# CountVectorizer\n",
    "# TfidfTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c53c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3255c96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism',\n",
      " 'comp.graphics',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'comp.windows.x',\n",
      " 'misc.forsale',\n",
      " 'rec.autos',\n",
      " 'rec.motorcycles',\n",
      " 'rec.sport.baseball',\n",
      " 'rec.sport.hockey',\n",
      " 'sci.crypt',\n",
      " 'sci.electronics',\n",
      " 'sci.med',\n",
      " 'sci.space',\n",
      " 'soc.religion.christian',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.mideast',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "pprint(list(newsgroups_train.target_names))\n",
    "\n",
    "# TAKES TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a02267e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comp.graphics', 'rec.motorcycles', 'rec.sport.hockey', 'sci.electronics', 'sci.med']\n",
      "From: tron@fafnir.la.locus.com (Michael Trofimoff)\n",
      "Subject: REQUEST: Gyro (souvlaki) sauce\n",
      "Organization: Locus Computing Corporation, Los Angeles, California\n",
      "sci.med\n",
      "sci.med\n",
      "rec.motorcycles\n",
      "sci.electronics\n",
      "sci.electronics\n",
      "rec.sport.hockey\n",
      "sci.electronics\n",
      "rec.sport.hockey\n",
      "rec.sport.hockey\n",
      "rec.sport.hockey\n",
      "rec.sport.hockey\n"
     ]
    }
   ],
   "source": [
    "# We defined the categories which we want to classify\n",
    "categories = ['rec.motorcycles', 'sci.electronics',\n",
    "              'comp.graphics', 'sci.med','rec.sport.hockey']\n",
    "\n",
    "# sklearn provides us with subset data for training and testing\n",
    "train_data = fetch_20newsgroups(subset='train',\n",
    "                                categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "print(train_data.target_names)\n",
    "\n",
    "print(\"\\n\".join(train_data.data[0].split(\"\\n\")[:3]))\n",
    "print(train_data.target_names[train_data.target[0]])\n",
    "\n",
    "# Let's look at categories of our first ten training data\n",
    "for t in train_data.target[:10]:\n",
    "    print(train_data.target_names[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d545594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds a dictionary of features and transforms documents to feature vectors and convert our text documents to a\n",
    "# matrix of token counts (CountVectorizer)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train_data.data)\n",
    "\n",
    "# transform a count matrix to a normalized tf-idf representation (tf-idf transformer)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b59fd6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "# training our classifier ; train_data.target will be having numbers assigned for each category in train data\n",
    "clf = knn.fit(X_train_tfidf, train_data.target)\n",
    "\n",
    "# Input Data to predict their classes of the given categories\n",
    "docs_new = ['I have a Harley Davidson and Yamaha.', 'I have a GTX 1050 GPU','Television discovery increased entertainment',\"Sports Minister Anurag Thakur on Sunday came hard on Hockey India for unilaterally deciding to pull out of next year's Commonwealth Games, saying the national federation is bound to consult with the government before taking any such step.\"]\n",
    "# building up feature vector of our input\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "# We call transform instead of fit_transform because it's already been fit\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8556bf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'I have a Harley Davidson and Yamaha.' => rec.motorcycles\n",
      "'I have a GTX 1050 GPU' => sci.med\n",
      "'Television discovery increased entertainment' => sci.electronics\n",
      "\"Sports Minister Anurag Thakur on Sunday came hard on Hockey India for unilaterally deciding to pull out of next year's Commonwealth Games, saying the national federation is bound to consult with the government before taking any such step.\" => rec.sport.hockey\n"
     ]
    }
   ],
   "source": [
    "# predicting the category of our input text: Will give out number for category\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, train_data.target_names[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5655172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We got an accuracy of 82.67766497461929 % over the test data.\n"
     ]
    }
   ],
   "source": [
    "# We can use Pipeline to add vectorizer -> transformer -> classifier all in a one compound classifier\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', knn),\n",
    "])\n",
    "# Fitting our train data to the pipeline\n",
    "text_clf.fit(train_data.data, train_data.target)\n",
    "\n",
    "# Test data \n",
    "test_data = fetch_20newsgroups(subset='test',\n",
    "                               categories=categories, shuffle=True, random_state=42)\n",
    "docs_test = test_data.data\n",
    "# Predicting our test data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "print('We got an accuracy of',np.mean(predicted == test_data.target)*100, '% over the test data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80cd66d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
