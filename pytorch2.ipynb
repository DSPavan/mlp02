{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df7b1d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f773935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "021242a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformations to be applied on images\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cee765f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "167bb9e91ffa4a0a9b9dd9e4391f5b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a35ecace624bf98d49e76a8eef39b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79eadb649d33453aa03e735b80b545c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7653411e273d4723987235b1ebe32367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce316748939b49dba96228859a979737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\train-images-idx3-ubyte.gz to ./MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6786290c2e4b473e866072d34df203ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\train-labels-idx1-ubyte.gz to ./MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43cc28a63f0b4fd6a2e1920530909100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ab1918ac5f47a98ccbcd1f4b3c24d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defining the training and testing set\n",
    "trainset = datasets.MNIST('./data', download=True, train=True, transform=transform)\n",
    "testset = datasets.MNIST('./', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4666ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining trainloader and testloader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40450fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# shape of training data\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c447c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xd90ccde2b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAANXElEQVR4nO3dX6xV9ZnG8efRoRfSBmGMhlCUHvRCbaKdoCGRkE4aGsdE/lx0hAR10prDRU2qmTiSzkU1kyZmxo4XGhsP0RQnjKQJMkqjoUpwcG4awKAiTPFokAInnCghCDcdPO9cnIU5hbN/+7D/rX14v5/kZO+93r3WerPDw1p7/dk/R4QAXP6uqLsBAL1B2IEkCDuQBGEHkiDsQBJ/1cuV2ebQP9BlEeHJpre1Zbd9t+0/2h62vb6dZQHoLrd6nt32lZIOSVom6aik3ZLWRMSBwjxs2YEu68aW/U5JwxHxaUT8WdJmSSvaWB6ALmon7PMk/WnC66PVtL9ge9D2Htt72lgXgDa1c4Busl2Fi3bTI2JI0pDEbjxQp3a27EclzZ/w+tuSjrfXDoBuaSfsuyXdZPs7tr8habWk1zvTFoBOa3k3PiLO2X5Y0nZJV0p6KSI+6lhnADqq5VNvLa2M7+xA13XlohoA0wdhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0n0dMhmTD/Nfn14bGysa+vev39/sb58+fJi/bPPPutkO9MeW3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJRXFF06NChYn1gYKBHnVzs0UcfLdafffbZHnXSXxqN4trWRTW2D0v6UtJXks5FxKJ2lgegezpxBd3fRsTnHVgOgC7iOzuQRLthD0m/t73X9uBkb7A9aHuP7T1trgtAG9rdjb8rIo7bvlbSW7b/NyJ2TXxDRAxJGpI4QAfUqa0te0Qcrx5HJW2VdGcnmgLQeS2H3fZM2986/1zSDyWV70kEUJuWz7PbHtD41lwa/zrwnxHxyybzsBs/zdx4443F+tNPP12sb968uWHt3nvvLc573333Fetnz54t1teuXduwtm3btuK801nHz7NHxKeSbmu5IwA9xak3IAnCDiRB2IEkCDuQBGEHkuCnpFE0PDxcrK9cubLlZS9YsKBYb3bqbebMmcX6zTff3LB2OZ96a4QtO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTB/ezoqiuuaLw9mTVrVg87AVt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiC8+zoqvvvv79h7bHHHmtr2adOnSrWd+3a1dbyLzdNt+y2X7I9anv/hGlzbL9l++PqcXZ32wTQrqnsxv9G0t0XTFsvaUdE3CRpR/UaQB9rGvaI2CXp5AWTV0jaWD3fKGllZ9sC0Gmtfme/LiJGJCkiRmxf2+iNtgclDba4HgAd0vUDdBExJGlIkmxHt9cHYHKtnno7YXuuJFWPo51rCUA3tBr21yU9WD1/UNJrnWkHQLc4orxnbfsVSd+XdI2kE5J+Iem/JP1W0vWSjkj6UURceBBvsmWxG3+ZWbx4cbG+c+fOhrUZM2a0te4jR44U6wMDA20tf7qKCE82vel39ohY06D0g7Y6AtBTXC4LJEHYgSQIO5AEYQeSIOxAEtzieplbuHBhsd7sNtHVq1cX6w899FCx3s7ptdOnTxfrTz75ZMvLzogtO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwXn2aWDlypXF+rJlyxrWli9fXpx3eHi4WF+6dGmx3uwW6ZLt27cX688991yx/uabb7a87ozYsgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEk1/SrqjK0v6U9I33HBDsb5t27Zi/dZbb+1kO5fkiivK24OxsbFi/e23325Ye/7554vzvvYawxG0otFPSbNlB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkuJ+9A+bPn1+sb9mypVi/5ZZbivVeXgtxoWbn0Zv1dv311zesvf/++y31hNY03bLbfsn2qO39E6Y9YfuY7X3V3z3dbRNAu6ayG/8bSXdPMv2ZiLi9+nujs20B6LSmYY+IXZJO9qAXAF3UzgG6h21/UO3mz270JtuDtvfY3tPGugC0qdWw/1rSQkm3SxqR9KtGb4yIoYhYFBGLWlwXgA5oKewRcSIivoqIMUkbJN3Z2bYAdFpLYbc9d8LLVZL2N3ovgP7Q9H52269I+r6kaySdkPSL6vXtkkLSYUnrImKk6cqm8f3sV111VcPau+++W5z3tttu63Q7PWNPemv019q5BuCZZ54p1h9//PFivdk1AFk1up+96UU1EbFmkskvtt0RgJ7iclkgCcIOJEHYgSQIO5AEYQeS4Kekp2jWrFkNa1988UUPO+msZsMm79u3r1ifN29esb527dpLbelr69atK9ZffJGTQpPhp6SB5Ag7kARhB5Ig7EAShB1IgrADSRB2IAnOs09RP59nP3bsWMPaAw88UJx37969xfqZM2eK9SVLlhTr77zzTrFesnv37mJ9xYoVxfro6GjL657OOM8OJEfYgSQIO5AEYQeSIOxAEoQdSIKwA0kwZPMUla5HOHXqVHHeq6++ulhvdj548+bNxfrLL7/csNbsfvR2HThwoFjfunVrw9qqVauK895xxx3F+rJly4r1TZs2FevZsGUHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSS4n70DFi9eXKwvXbq0WN+yZUux/sknn1xyT/2im78DcOTIkWJ9YGCgreVPVy3fz257vu2dtg/a/sj2z6rpc2y/Zfvj6nF2p5sG0DlT2Y0/J+kfI+JmSYsl/dT2LZLWS9oRETdJ2lG9BtCnmoY9IkYi4r3q+ZeSDkqaJ2mFpI3V2zZKWtmlHgF0wCVdG297gaTvSfqDpOsiYkQa/w/B9rUN5hmUNNhmnwDaNOWw2/6mpC2SHomI0/akxwAuEhFDkoaqZVyWB+iA6WBKp95sz9B40DdFxKvV5BO251b1uZJy/pQnME00PfXm8U34RkknI+KRCdP/TdIXEfGU7fWS5kTEPzVZFlv2ZDj11nuNTr1NZTf+Lkn3S/rQ9r5q2s8lPSXpt7Z/IumIpB91oE8AXdI07BHxP5IafUH/QWfbAdAtXC4LJEHYgSQIO5AEYQeSIOxAEvyUNLrq7NmzDWsvvPBCcd5169YV66WhqnExtuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATn2dFV586da1jbsGFDcd6xsbFi/Y033mipp6zYsgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEgzZDFxmWh6yGcDlgbADSRB2IAnCDiRB2IEkCDuQBGEHkmgadtvzbe+0fdD2R7Z/Vk1/wvYx2/uqv3u63y6AVjW9qMb2XElzI+I929+StFfSSkl/L+lMRDw95ZVxUQ3QdY0uqpnK+Owjkkaq51/aPihpXmfbA9Btl/Sd3fYCSd+T9Idq0sO2P7D9ku3ZDeYZtL3H9p72WgXQjilfG2/7m5L+W9IvI+JV29dJ+lxSSPoXje/q/7jJMtiNB7qs0W78lMJue4ak30naHhH/Pkl9gaTfRcR3myyHsANd1vKNMLYt6UVJBycGvTpwd94qSfvbbRJA90zlaPwSSe9K+lDS+d/2/bmkNZJu1/hu/GFJ66qDeaVlsWUHuqyt3fhOIexA93E/O5AcYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IImmPzjZYZ9L+mzC62uqaf2oX3vr174kemtVJ3u7oVGhp/ezX7Rye09ELKqtgYJ+7a1f+5LorVW96o3deCAJwg4kUXfYh2pef0m/9tavfUn01qqe9Fbrd3YAvVP3lh1AjxB2IIlawm77btt/tD1se30dPTRi+7DtD6thqGsdn64aQ2/U9v4J0+bYfsv2x9XjpGPs1dRbXwzjXRhmvNbPru7hz3v+nd32lZIOSVom6aik3ZLWRMSBnjbSgO3DkhZFRO0XYNheKumMpJfPD61l+18lnYyIp6r/KGdHxON90tsTusRhvLvUW6Nhxv9BNX52nRz+vBV1bNnvlDQcEZ9GxJ8lbZa0ooY++l5E7JJ08oLJKyRtrJ5v1Pg/lp5r0FtfiIiRiHivev6lpPPDjNf62RX66ok6wj5P0p8mvD6q/hrvPST93vZe24N1NzOJ684Ps1U9XltzPxdqOox3L10wzHjffHatDH/erjrCPtnQNP10/u+uiPgbSX8n6afV7iqm5teSFmp8DMARSb+qs5lqmPEtkh6JiNN19jLRJH315HOrI+xHJc2f8Prbko7X0MekIuJ49TgqaavGv3b0kxPnR9CtHkdr7udrEXEiIr6KiDFJG1TjZ1cNM75F0qaIeLWaXPtnN1lfvfrc6gj7bkk32f6O7W9IWi3p9Rr6uIjtmdWBE9meKemH6r+hqF+X9GD1/EFJr9XYy1/ol2G8Gw0zrpo/u9qHP4+Inv9JukfjR+Q/kfTPdfTQoK8BSe9Xfx/V3ZukVzS+W/d/Gt8j+omkv5a0Q9LH1eOcPurtPzQ+tPcHGg/W3Jp6W6Lxr4YfSNpX/d1T92dX6KsnnxuXywJJcAUdkARhB5Ig7EAShB1IgrADSRB2IAnCDiTx/1DAWCVjtgu7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizing the training images\n",
    "plt.imshow(images[0].numpy().squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffdd3315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the model architecture\n",
    "class Net(nn.Module):   \n",
    "  def __init__(self):\n",
    "      super(Net, self).__init__()\n",
    "\n",
    "      self.cnn_layers = nn.Sequential(\n",
    "          # Defining a 2D convolution layer\n",
    "          nn.Conv2d(1, 4, kernel_size=3, stride=1, padding=1),\n",
    "          nn.BatchNorm2d(4),\n",
    "          nn.ReLU(inplace=True),\n",
    "          nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "          # Defining another 2D convolution layer\n",
    "          nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "          nn.BatchNorm2d(4),\n",
    "          nn.ReLU(inplace=True),\n",
    "          nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "      )\n",
    "\n",
    "      self.linear_layers = nn.Sequential(\n",
    "          nn.Linear(4 * 7 * 7, 10)\n",
    "      )\n",
    "        \n",
    "    # Defining the forward pass    \n",
    "  def forward(self, x):\n",
    "      x = self.cnn_layers(x)\n",
    "      x = x.view(x.size(0), -1)\n",
    "      x = self.linear_layers(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7813cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the model\n",
    "model = Net()\n",
    "# defining the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "# defining the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce89d833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (cnn_layers): Sequential(\n",
      "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=196, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "710b451b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training loss: 0.19083692686163636\n",
      "Epoch 2 - Training loss: 0.09914911893888442\n",
      "Epoch 3 - Training loss: 0.08635407990452323\n",
      "Epoch 4 - Training loss: 0.07956658570673754\n",
      "Epoch 5 - Training loss: 0.07683774418652312\n",
      "Epoch 6 - Training loss: 0.07474822365740405\n",
      "Epoch 7 - Training loss: 0.07061297971276698\n",
      "Epoch 8 - Training loss: 0.06816156751248859\n",
      "Epoch 9 - Training loss: 0.06584377995039871\n",
      "Epoch 10 - Training loss: 0.06436525554178274\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "          images = images.cuda()\n",
    "          labels = labels.cuda()\n",
    "\n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        #This is where the model learns by backpropagating\n",
    "        loss.backward()\n",
    "        \n",
    "        #And optimizes its weights here\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(i+1, running_loss/len(trainloader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7abbd218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Images Tested = 10000\n",
      "\n",
      "Model Accuracy = 0.9737\n"
     ]
    }
   ],
   "source": [
    "# getting predictions on test set and measuring the performance\n",
    "correct_count, all_count = 0, 0\n",
    "for images,labels in testloader:\n",
    "  for i in range(len(labels)):\n",
    "    if torch.cuda.is_available():\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "    img = images[i].view(1, 1, 28, 28)\n",
    "    with torch.no_grad():\n",
    "        logps = model(img)\n",
    "\n",
    "    \n",
    "    ps = torch.exp(logps)\n",
    "    probab = list(ps.cpu()[0])\n",
    "    pred_label = probab.index(max(probab))\n",
    "    true_label = labels.cpu()[i]\n",
    "    if(true_label == pred_label):\n",
    "      correct_count += 1\n",
    "    all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f9e79e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.pluralsight.com/guides/image-classification-with-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19961912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
